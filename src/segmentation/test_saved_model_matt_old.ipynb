{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbb5044",
   "metadata": {},
   "source": [
    "This notebook to test the results of a trained segmentation model. This notebook will apply the segmentation model to any GLIMS_ID and produce a list of segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from helpers import read, preprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2843d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.mask import mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a12cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import imageio.v2 as imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ed1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from inference.cnn import UNet, conv_block\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce529af2-d5bc-4109-bae1-4e1c85d0b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = torch.load(\"model\", map_location=torch.device('cpu')) #for cpu\n",
    "#torch_model = torch.load(\"model\") #for gpu\n",
    "torch_model.to(device)\n",
    "torch_model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc271e0b-372f-4ecf-aa2f-58d7317f2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define inputs\n",
    "\n",
    "common_bands = ['blue','green','red','nir','swir','thermal']\n",
    "dim = (128,128)\n",
    "\n",
    "data_label = \"full_time_series_c02_t1_l2\"\n",
    "glacier_view_dir = os.path.join(os.path.expanduser(\"~\"),\n",
    "    \"Desktop\", \"projects\", \"GlacierView\")\n",
    "ee_data_dir = os.path.join(glacier_view_dir,  \"src\", \"earth_engine\",\"data\",\"ee_landing_zone\",data_label)                      \n",
    "landsat_dir = os.path.join(ee_data_dir, \"landsat\")\n",
    "dem_dir = os.path.join(ee_data_dir, \"dems\")\n",
    "masks_dir = os.path.join(glacier_view_dir, \"src\",\"segmentation\",\"training\",\"data\",\"masks_staging_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc44a80-76ad-4f00-9e08-008f72c579e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dir = os.path.join(glacier_view_dir,\"src\",\"earth_engine\",\"data\",\"processed_metadata\",data_label)\n",
    "filtered_inference_df = pd.read_csv(os.path.join(metadata_dir,\"filtered_inference_data_summer_months.csv\"))\n",
    "print(filtered_inference_df.shape)\n",
    "filtered_inference_df = filtered_inference_df[filtered_inference_df['geog_area_rollup'] == \"Europe\"]\n",
    "hq_file_names = sorted(filtered_inference_df.file_name)\n",
    "print(filtered_inference_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b17f0f-36b9-4b14-ac26-2e593afa4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_glac_idx = 130\n",
    "example_file_idx = 2\n",
    "\n",
    "example_glacier_name = os.path.join(landsat_dir,os.listdir(landsat_dir)[example_glac_idx])\n",
    "example_glacier_dir = os.path.join(landsat_dir,example_glacier_name)\n",
    "\n",
    "example_file_name = os.listdir(example_glacier_dir)[example_file_idx]\n",
    "\n",
    "\n",
    "print(example_file_name)\n",
    "\n",
    "img = rasterio.open(os.path.join(landsat_dir, example_glacier_name, example_file_name)).read()\n",
    "\n",
    "fig, axs = plt.subplots(2,10,figsize=(20, 5))\n",
    "for i in range(2):\n",
    "    for j in range(10):\n",
    "        if i==1 and j==9:\n",
    "            pass\n",
    "        else:\n",
    "            axs[i,j].imshow(img[10*i+j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc2a14-03fe-4be7-96e3-8e8cc71258b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_glac_idx = 129\n",
    "example_file_idx = 28\n",
    "\n",
    "example_glacier_name = os.path.join(landsat_dir,os.listdir(landsat_dir)[example_glac_idx])\n",
    "example_glacier_dir = os.path.join(landsat_dir,example_glacier_name)\n",
    "\n",
    "example_file_name = os.listdir(example_glacier_dir)[example_file_idx]\n",
    "\n",
    "\n",
    "print(example_file_name)\n",
    "\n",
    "img = rasterio.open(os.path.join(landsat_dir, example_glacier_name, example_file_name)).read()\n",
    "\n",
    "fig, axs = plt.subplots(2,10,figsize=(20, 5))\n",
    "for i in range(2):\n",
    "    for j in range(10):\n",
    "        if i==1 and j==9:\n",
    "            pass\n",
    "        else:\n",
    "            axs[i,j].imshow(img[10*i+j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d47409-b8a1-424d-88a0-a9dc42a83523",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_glac_idx = 129\n",
    "example_file_idx = 0\n",
    "\n",
    "example_glacier_name = os.path.join(landsat_dir,os.listdir(landsat_dir)[example_glac_idx])\n",
    "example_glacier_dir = os.path.join(landsat_dir,example_glacier_name)\n",
    "\n",
    "example_file_name = os.listdir(example_glacier_dir)[example_file_idx]\n",
    "\n",
    "\n",
    "print(example_file_name)\n",
    "\n",
    "img = rasterio.open(os.path.join(landsat_dir, example_glacier_name, example_file_name)).read()\n",
    "\n",
    "fig, axs = plt.subplots(2,10,figsize=(20, 5))\n",
    "for i in range(2):\n",
    "    for j in range(10):\n",
    "        if i==1 and j==9:\n",
    "            pass\n",
    "        else:\n",
    "            axs[i,j].imshow(img[10*i+j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307588c-ba41-4071-be26-aa72b3059814",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ffdbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for glims_id in np.unique(filtered_inference_df.glims_id):\n",
    "\n",
    "    PROB_THRESH = 0.5\n",
    "    \n",
    "    \n",
    "    glacier_dir = os.path.join(landsat_dir, glims_id)\n",
    "    dem_path = os.path.join(dem_dir, f\"{glims_id}_NASADEM.tif\")\n",
    "\n",
    "\n",
    "    mask_file_name = f\"{glims_id}.tif\"\n",
    "    mask = Image.open(os.path.join(masks_dir, mask_file_name))\n",
    "    mask = np.expand_dims(np.array(mask),2)\n",
    "    mask = {mask_file_name: mask}\n",
    "\n",
    "    #read and preprocess images\n",
    "    images = read.get_rasters(glacier_dir)\n",
    "    single_key = list(images.keys())[0]\n",
    "    original_sizes = [images[key].shape[:-1] for key in images if key in hq_file_names]\n",
    "    \n",
    "    nimages = preprocess.get_common_bands(images,common_bands)\n",
    "    nimages = preprocess.normalize_rasters(nimages)\n",
    "    nimages = preprocess.resize_rasters(nimages,dim)\n",
    "\n",
    "\n",
    "    #read and preprocess dems\n",
    "    dem = read.get_dem(dem_path)\n",
    "    \n",
    "    dem_key = list(dem.keys())[0]\n",
    "    dem = preprocess.resize_rasters(dem, dim)\n",
    "    dem = preprocess.normalize_rasters(dem)\n",
    "\n",
    "    #preprocess masks\n",
    "    mask = preprocess.resize_rasters(mask,dim)\n",
    "    mask = list(mask.values())[0]\n",
    "\n",
    "    # combine images and dems - high quality only\n",
    "    hq_list = list(pd.Series(nimages.keys())[list(pd.Series(list(nimages.keys())).isin(hq_file_names))])\n",
    "    combined_images_and_dems = [np.concatenate((nimages[file_name], dem[dem_key]),axis = 2) for file_name in sorted(hq_list)]\n",
    "\n",
    "    #process data\n",
    "    X = np.stack(combined_images_and_dems)\n",
    "    X = np.nan_to_num(X, copy=True, nan=0.0)\n",
    "    \n",
    "    X_smoothed = X #gaussian(X, sigma = [0.5,0,0,0], mode = 'nearest') \n",
    "    image_file_names_ordered = sorted(hq_list)\n",
    "    image_dates = [datetime.strptime(f.split(\"_\")[1],'%Y-%m-%d') for f in image_file_names_ordered]\n",
    "\n",
    "    inputs = torch.tensor(X_smoothed)\n",
    "\n",
    "    inputs = inputs.permute(0,3,1,2)\n",
    "    SMOOTH_FACTOR = 0\n",
    "    \n",
    "    green = inputs[:,1,:,:]\n",
    "    swir = inputs[:,4,:,:]\n",
    "    nir = inputs[:,3,:,:]\n",
    "    \n",
    "    ndsi = (green - swir)/(green + swir+SMOOTH_FACTOR)\n",
    "    ndsi = ndsi.unsqueeze(dim=1)\n",
    "    inputs = torch.cat((ndsi, inputs), dim=1)\n",
    "    \n",
    "    ndwi = (green - nir)/(green + nir+SMOOTH_FACTOR)\n",
    "    ndwi = ndwi.unsqueeze(dim=1)\n",
    "    inputs = torch.cat((ndwi, inputs), dim=1)\n",
    "    prediction_dataset = TensorDataset(inputs) # create your datset\n",
    "    prediction_dataloader = DataLoader(prediction_dataset, batch_size=64,shuffle=False) # create your dataloader\n",
    "\n",
    "    predictions = []\n",
    "    for i in tqdm(prediction_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = torch_model.forward(i[0].to(device=device,dtype=torch.float))\n",
    "            outputs = torch.softmax(outputs, dim=1)\n",
    "            outputs = outputs[:,1,:,:].unsqueeze(1)\n",
    "        m = torch.nn.Threshold(PROB_THRESH, 0)\n",
    "        predictions.append(m(outputs))\n",
    "        \n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "\n",
    "    resized_predictions = []\n",
    "    area_per_pred = []\n",
    "    resized_imgs = []\n",
    "    for index, size in enumerate(original_sizes):\n",
    "        resize = torchvision.transforms.Resize(size, antialias=True)\n",
    "        pred = resize(predictions[index])\n",
    "        resized_imgs.append(pred.detach().cpu().numpy()[0])\n",
    "        area = pred.sum().detach().cpu().numpy()\n",
    "        area = area*0.0009 #to convert area\n",
    "        area_per_pred.append(area)\n",
    "        resized_predictions.append(resize(predictions[index]))\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(area_per_pred, image_dates)\n",
    "    \n",
    "    df[glims_id] = df[0]\n",
    "    df.drop([0],axis=1)\n",
    "    df =  df[glims_id]\n",
    "    df = df.to_frame()\n",
    "    df.index.names = ['Dates']\n",
    "    df.to_csv(f\"{glims_id}_areas.csv\")\n",
    "\n",
    "    ts_output_dir = \"time_series\"\n",
    "    is_exist = os.path.exists(ts_output_dir)\n",
    "    if not is_exist:\n",
    "       os.makedirs(ts_output_dir)\n",
    "    df.plot(figsize=(10,5), ylabel=\"Area in km sq.\", xlabel=\"Years\", title=f\"Area vs Time plot for {glims_id} Glacier\")\n",
    "    mo = df.groupby(pd.PeriodIndex(df.index, freq=\"Y\"))[df.columns[0]].mean()\n",
    "    mo.plot()\n",
    "    plt.legend([\"Area at each time point\",\"Annual Mean Area\"])\n",
    "    plt.savefig(os.path.join(ts_output_dir, f\"{glims_id}.png\"))\n",
    "\n",
    "    #create GIF\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "\n",
    "    gif_creation_dir = os.path.join(\"tmp\", \"gif_creation\")\n",
    "    is_exist = os.path.exists(gif_creation_dir)\n",
    "    if not is_exist:\n",
    "       os.makedirs(gif_creation_dir)\n",
    "\n",
    "    gif_output_dir = \"gifs\"\n",
    "    is_exist = os.path.exists(gif_output_dir)\n",
    "    if not is_exist:\n",
    "       os.makedirs(gif_output_dir)\n",
    "    \n",
    "    # gif_creation_dir = os.path.join(os.path.expanduser(\"~\"), \"PycharmProjects\",\"glacier-view-analysis\", \"src\", \"segmentation\",\"tmp\",\"gif_creation\")\n",
    "    # gif_output_dir = os.path.join(os.path.expanduser(\"~\"), \"PycharmProjects\",\"glacier-view-analysis\", \"src\", \"segmentation\", \"gifs\")\n",
    "    \n",
    "    for f in os.listdir(gif_creation_dir):\n",
    "        os.remove(os.path.join(gif_creation_dir, f))\n",
    "    \n",
    "    for i in range(X_smoothed.shape[0]):\n",
    "        if i%1 == 0: #ignores 80% of images to run faster\n",
    "            fig, axs = plt.subplots(2,3, figsize=(10,10)) ##update the number of suplots to equal the number of layers you want to display\n",
    "            fig.suptitle(image_file_names_ordered[i])\n",
    "            # axs[0].imshow(predictions[i,0,:,:],alpha=0.1)\n",
    "            axs[0,0].imshow((X_smoothed[i,:,:,:][:,:,[2,1,0]]))\n",
    "            axs[0,0].title.set_text('RGB')\n",
    "            axs[0,1].imshow((ndsi[i,0,:,:]))\n",
    "            axs[0,1].title.set_text('NDSI')\n",
    "            axs[0,2].imshow(X_smoothed[i,:,:,:][:,:,5])\n",
    "            axs[0,2].title.set_text('Thermal')\n",
    "            axs[1,0].imshow(X_smoothed[i,:,:,:][:,:,6])\n",
    "            axs[1,0].title.set_text('DEM')\n",
    "            axs[1,1].imshow((X_smoothed[i,:,:,:][:,:,[2,1,0]]))\n",
    "            axs[1,1].imshow(predictions[i,0,:,:],alpha=0.5)\n",
    "            axs[1,1].title.set_text('Prediction')\n",
    "            axs[1,2].imshow(mask)\n",
    "            axs[1,2].title.set_text('Ground truth')\n",
    "                        \n",
    "    \n",
    "            plt.savefig(os.path.join(gif_creation_dir,f'{image_file_names_ordered[i]}_final.png'), dpi = 100)\n",
    "            # plt.show()\n",
    "    \n",
    "    with imageio.get_writer(os.path.join(gif_output_dir,f\"{glims_id}_final_NEWEST.gif\"), mode='I') as writer:\n",
    "        for filename in sorted(os.listdir(gif_creation_dir)):\n",
    "            image = imageio.imread(os.path.join(gif_creation_dir,filename))\n",
    "            writer.append_data(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7234274-6431-41df-9030-7083b2c1dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for glims_id in np.unique(filtered_inference_df.glims_id[0]):\n",
    "\n",
    "    PROB_THRESH = 0.5\n",
    "    \n",
    "    \n",
    "    glacier_dir = os.path.join(landsat_dir, glims_id)\n",
    "    dem_path = os.path.join(dem_dir, f\"{glims_id}_NASADEM.tif\")\n",
    "\n",
    "\n",
    "    mask_file_name = f\"{glims_id}.tif\"\n",
    "    mask = Image.open(os.path.join(masks_dir, mask_file_name))\n",
    "    mask = np.expand_dims(np.array(mask),2)\n",
    "    mask = {mask_file_name: mask}\n",
    "\n",
    "    #read and preprocess images\n",
    "    images = read.get_rasters(glacier_dir)\n",
    "    single_key = list(images.keys())[0]\n",
    "    original_sizes = [images[key].shape[:-1] for key in images if key in hq_file_names]\n",
    "    \n",
    "    nimages = preprocess.get_common_bands(images,common_bands)\n",
    "    nimages = preprocess.normalize_rasters(nimages)\n",
    "    nimages = preprocess.resize_rasters(nimages,dim)\n",
    "\n",
    "    hq_list = list(pd.Series(nimages.keys())[list(pd.Series(list(nimages.keys())).isin(hq_file_names))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1178c-8e37-483f-bfe5-e41f9fb630ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import random\n",
    "    fig, ax = plt.subplots(1,2, figsize = (10,6))\n",
    "    key = random.choice(list(nimages.keys()))\n",
    "    key_2 = random.choice(hq_list)\n",
    "    print(key)\n",
    "    ax[0].imshow(nimages[key][:,:,[2,1,0]])\n",
    "    ax[0].set_title(\"Non filtered\")\n",
    "    ax[1].imshow(nimages[key_2][:,:,[2,1,0]])\n",
    "    ax[1].set_title(\"Filtered\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f266c8-f0d6-4a3a-b5ae-8a0d293bd882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
