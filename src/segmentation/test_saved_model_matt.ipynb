{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbb5044",
   "metadata": {},
   "source": [
    "This notebook to test the results of a trained segmentation model. This notebook will apply the segmentation model to any GLIMS_ID and produce a list of segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from helpers import read, preprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2843d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.mask import mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a12cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import imageio.v2 as imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ed1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from inference.cnn import UNet, conv_block\n",
    "\n",
    "import torchvision\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ffdbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define inputs\n",
    "glims_id = 'G007026E45991N' #trient\n",
    "    \n",
    "PROB_THRESH = 0.5\n",
    "\n",
    "data_label = \"full_time_series_c02_t1_l2\"\n",
    "ee_data_dir = os.path.join(os.path.expanduser(\"~\"),\n",
    "    \"Desktop\", \"projects\", \"GlacierView\",  \"src\", \"earth_engine\",\"data\",\"ee_landing_zone\",data_label)\n",
    "dem_data_dir = os.path.join(os.path.expanduser(\"~\"),\n",
    "    \"Desktop\", \"projects\", \"GlacierView\", \"src\", \"earth_engine\",\"data\",\"ee_landing_zone\",\"full_time_series\")                         \n",
    "landsat_dir = os.path.join(ee_data_dir, \"landsat\")\n",
    "dem_dir = os.path.join(dem_data_dir, \"dems\")\n",
    "\n",
    "glacier_dir = os.path.join(landsat_dir, glims_id)\n",
    "dem_path = os.path.join(dem_dir, f\"{glims_id}_NASADEM.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa84777",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_bands = ['blue','green','red','nir','swir','thermal']\n",
    "dim = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84911059-01d4-4ed1-aaaf-6134571dbeab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = rasterio.open(glacier_dir+\"/\"+os.listdir(glacier_dir)[100]).read()\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2,ncols=10,figsize=(20, 5))\n",
    "plt.axis('off')\n",
    "for i in range(2):\n",
    "    for j in range(10):\n",
    "        if i==1 and j==9:\n",
    "            pass\n",
    "        else:\n",
    "            axs[i,j].imshow(dataset[10*i+j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fca868c-f533-4571-9d33-1443f50087d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = read.get_rasters(glacier_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ffe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and preprocess images\n",
    "sample_image_key = list(images.keys())[0]\n",
    "original_sizes = [images[sample_image_key].shape[:-1] for key in images.keys()]\n",
    "print(f\"Before preprocessing single image shape: {images[sample_image_key].shape}\")\n",
    "nimages = preprocess.get_common_bands(images,common_bands)\n",
    "nimages = preprocess.normalize_rasters(nimages)\n",
    "nimages = preprocess.resize_rasters(nimages,dim)\n",
    "print(f\"After preprocessing single image shape: {nimages[sample_image_key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efdbd2-fad8-4fa0-9a42-c773c64cd29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(nimages.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e63c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and preprocess dems\n",
    "\n",
    "dem = read.get_dem(dem_path)\n",
    "\n",
    "dem_key = list(dem.keys())[0]\n",
    "print(f\"Before preprocessing single dem shape: {dem[dem_key].shape}\")\n",
    "dem = preprocess.resize_rasters(dem, dim)\n",
    "dem = preprocess.normalize_rasters(dem)\n",
    "print(f\"After preprocessing single dem shape: {dem[dem_key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5beae76-5b57-4b8b-912e-b778ec2d6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_images_and_dems = [np.concatenate((nimages[file_name], dem[dem_key]),axis = 2) for file_name in sorted(nimages.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783786d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match images with labels\n",
    "X = np.stack(combined_images_and_dems)\n",
    "X = np.nan_to_num(X, copy=True, nan=0.0)\n",
    "\n",
    "X_smoothed = gaussian(X, sigma = [20,0,0,0], mode = 'reflect')\n",
    "image_file_names_ordered = sorted(nimages.keys())\n",
    "image_dates = [datetime.strptime(f.split(\"_\")[1],'%Y-%m-%d') for f in image_file_names_ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = torch.load(\"model\", map_location=torch.device('cpu')) #for cpu\n",
    "#torch_model = torch.load(\"model\") #for gpu\n",
    "torch_model.to(device)\n",
    "torch_model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27706af6-7c34-4484-9238-13020e3cb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(X_smoothed)\n",
    "\n",
    "inputs = inputs.permute(0,3,1,2)\n",
    "SMOOTH_FACTOR = 0\n",
    "\n",
    "green = inputs[:,1,:,:]\n",
    "swir = inputs[:,4,:,:]\n",
    "nir = inputs[:,3,:,:]\n",
    "\n",
    "ndsi = (green - swir)/(green + swir+SMOOTH_FACTOR)\n",
    "ndsi = ndsi.unsqueeze(dim=1)\n",
    "inputs = torch.cat((ndsi, inputs), dim=1)\n",
    "\n",
    "ndwi = (green - nir)/(green + nir+SMOOTH_FACTOR)\n",
    "ndwi = ndwi.unsqueeze(dim=1)\n",
    "inputs = torch.cat((ndwi, inputs), dim=1)\n",
    "\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e77cd-4eb4-4760-838e-6807d6074e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataset = TensorDataset(inputs) # create your datset\n",
    "prediction_dataloader = DataLoader(prediction_dataset, batch_size=64,shuffle=False) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b40e8-929b-4755-95eb-3424227054f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in tqdm(prediction_dataloader):\n",
    "    with torch.no_grad():\n",
    "        outputs = torch_model.forward(i[0].to(device=device,dtype=torch.float))\n",
    "        outputs = torch.softmax(outputs, dim=1)\n",
    "        outputs = outputs[:,1,:,:].unsqueeze(1)\n",
    "    m = torch.nn.Threshold(PROB_THRESH, 0)\n",
    "    predictions.append(m(outputs))\n",
    "    \n",
    "predictions = torch.cat(predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624df8c-bca8-4638-a108-f6b101c6c8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resized_predictions = []\n",
    "area_per_pred = []\n",
    "resized_imgs = []\n",
    "for index, size in enumerate(original_sizes):\n",
    "    resize = torchvision.transforms.Resize(size, antialias=True)\n",
    "    pred = resize(predictions[index])\n",
    "    resized_imgs.append(pred.detach().cpu().numpy()[0])\n",
    "    area = pred.sum().detach().cpu().numpy()\n",
    "    area = area*0.0009\n",
    "    area_per_pred.append(area)\n",
    "    resized_predictions.append(resize(predictions[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d7254-3031-4f2f-bf51-d3bc08b3266a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(area_per_pred, image_dates)\n",
    "\n",
    "df[\"G007026E45991N\"] = df[0]\n",
    "df.drop([0],axis=1)\n",
    "df =  df[\"G007026E45991N\"]\n",
    "df = df.to_frame()\n",
    "df.index.names = ['Dates']\n",
    "df.to_csv(\"trient_areas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00144b2b-1007-44e8-a145-5d6930a42ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_output_dir = \"time_series\"\n",
    "is_exist = os.path.exists(ts_output_dir)\n",
    "if not is_exist:\n",
    "   os.makedirs(ts_output_dir)\n",
    "df.plot(figsize=(10,5), ylabel=\"Area in km sq.\", xlabel=\"Years\", title=\"Area vs Time plot for Trient Glacier\")\n",
    "mo = df.groupby(pd.PeriodIndex(df.index, freq=\"Y\"))[df.columns[0]].mean()\n",
    "mo.plot()\n",
    "plt.legend([\"Area at each time point\",\"Annual Mean Area\"])\n",
    "plt.savefig(os.path.join(ts_output_dir, f\"{glims_id}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41b554-e3ba-4897-a275-c84ad7e7c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_keys = list(images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8cb1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create GIF\n",
    "predictions = predictions.detach().cpu().numpy()\n",
    "\n",
    "gif_creation_dir = os.path.join(\"tmp\", \"gif_creation\")\n",
    "is_exist = os.path.exists(gif_creation_dir)\n",
    "if not is_exist:\n",
    "   os.makedirs(gif_creation_dir)\n",
    "\n",
    "gif_output_dir = \"gifs\"\n",
    "is_exist = os.path.exists(gif_output_dir)\n",
    "if not is_exist:\n",
    "   os.makedirs(gif_output_dir)\n",
    "\n",
    "\n",
    "# gif_creation_dir = os.path.join(os.path.expanduser(\"~\"), \"PycharmProjects\",\"glacier-view-analysis\", \"src\", \"segmentation\",\"tmp\",\"gif_creation\")\n",
    "# gif_output_dir = os.path.join(os.path.expanduser(\"~\"), \"PycharmProjects\",\"glacier-view-analysis\", \"src\", \"segmentation\", \"gifs\")\n",
    "\n",
    "for f in os.listdir(gif_creation_dir):\n",
    "    os.remove(os.path.join(gif_creation_dir, f))\n",
    "\n",
    "for i in range(X_smoothed.shape[0]):\n",
    "    if i%1 == 0: #ignores 80% of images to run faster\n",
    "        fig, axs = plt.subplots(2, figsize=(10,10)) ##update the number of suplots to equal the number of layers you want to display\n",
    "        fig.suptitle(image_file_names_ordered[i])\n",
    "        axs[0].imshow((X_smoothed[i,:,:,:][:,:,[2,1,0]]))\n",
    "        # axs[0].imshow(predictions[i,0,:,:],alpha=0.1)\n",
    "        axs[1].imshow((X_smoothed[i,:,:,:][:,:,[2,1,0]]))\n",
    "        axs[1].imshow(predictions[i,0,:,:],alpha=0.2)\n",
    "\n",
    "        plt.savefig(os.path.join(gif_creation_dir,f'{image_file_names_ordered[i]}_final.png'), dpi = 100)\n",
    "        # plt.show()\n",
    "\n",
    "with imageio.get_writer(os.path.join(gif_output_dir,f\"{glims_id}_final.gif\"), mode='I') as writer:\n",
    "    for filename in sorted(os.listdir(gif_creation_dir)):\n",
    "        image = imageio.imread(os.path.join(gif_creation_dir,filename))\n",
    "        writer.append_data(image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
