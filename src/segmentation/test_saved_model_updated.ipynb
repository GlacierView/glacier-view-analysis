{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbb5044",
   "metadata": {},
   "source": [
    "This notebook to test the results of a trained segmentation model. This notebook will apply the segmentation model to any GLIMS_ID and produce a list of segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f81612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.expanduser(\"~\"),\"PycharmProjects\",\"glacier-view-analysis\", \"src\",\"segmentation\",\"helpers\"))\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import read\n",
    "import preprocess\n",
    "import landsat_bands\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from skimage.filters import gaussian\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ffdbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define inputs\n",
    "# glims_id = 'G006628E45300N' \n",
    "# glims_id = 'G006819E45785N' #lex blanche\n",
    "glims_id = 'G007026E45991N' #trient\n",
    "#glims_id = 'G086519E27919N'\n",
    "PROB_THRESH = 0.3\n",
    "\n",
    "data_label = \"full_time_series\"\n",
    "ee_data_dir = os.path.join(os.path.expanduser(\"~\"),\n",
    "    \"PycharmProjects\",\"glacier-view-analysis\",  \"src\", \"earth_engine\",\"data\",\"ee_landing_zone\",data_label)\n",
    "dem_data_dir = os.path.join(os.path.expanduser(\"~\"),\n",
    "    \"PycharmProjects\",\"glacier-view-analysis\", \"src\", \"earth_engine\",\"data\",\"ee_landing_zone\",\"full_time_series\")                         \n",
    "landsat_dir = os.path.join(ee_data_dir, \"landsat\")\n",
    "dem_dir = os.path.join(dem_data_dir, \"dems\")\n",
    "\n",
    "glacier_dir = os.path.join(landsat_dir, glims_id)\n",
    "dem_path = os.path.join(dem_dir, f\"{glims_id}_NASADEM.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa84777",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_bands = ['blue','green','red','nir','swir','thermal','swir_2']\n",
    "dim = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ffe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and preprocess images\n",
    "\n",
    "images = read.get_rasters(glacier_dir)\n",
    "\n",
    "sample_image_key = list(images.keys())[0]\n",
    "print(f\"Before preprocessing single image shape: {images[sample_image_key].shape}\")\n",
    "images = preprocess.get_common_bands(images,common_bands)\n",
    "images = preprocess.normalize_rasters(images)\n",
    "images = preprocess.resize_rasters(images,dim)\n",
    "print(f\"After preprocessing single image shape: {images[sample_image_key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e63c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and preprocess dems\n",
    "\n",
    "dem = read.get_dem(dem_path)\n",
    "\n",
    "dem_key = list(dem.keys())[0]\n",
    "print(f\"Before preprocessing single dem shape: {dem[dem_key].shape}\")\n",
    "dem = preprocess.resize_rasters(dem, dim)\n",
    "dem = preprocess.normalize_rasters(dem)\n",
    "print(f\"After preprocessing single dem shape: {dem[dem_key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5beae76-5b57-4b8b-912e-b778ec2d6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_images_and_dems = [np.concatenate((images[file_name], dem[dem_key]),axis = 2) for file_name in sorted(images.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783786d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match images with labels\n",
    "X = np.stack(combined_images_and_dems)\n",
    "X_smoothed = gaussian(X, sigma = [20,0,0,0], mode = 'reflect')\n",
    "image_file_names_ordered = sorted(images.keys())\n",
    "image_dates = [datetime.strptime(f.split(\"_\")[1],'%Y-%m-%d') for f in image_file_names_ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a94df-c3d7-4d0c-bd53-977645fa7200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0c984-66d4-4ed6-a96f-54dfaa0790ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.nn.functional import interpolate\n",
    "# from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class, freeze_encoder=True):\n",
    "        self.n_class = n_class\n",
    "        self.freeze_encoder = freeze_encoder\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        resnet = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "\n",
    "        if self.freeze_encoder:\n",
    "            for param in resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.resnet[0] = nn.Conv2d(10, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.deconv1 = nn.ConvTranspose2d(2048, 1024, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(1024)\n",
    "        self.deconv2 = nn.ConvTranspose2d(2048, 512, kernel_size=3, stride=2, padding=1, dilation=1,\n",
    "                                          output_padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.deconv3 = nn.ConvTranspose2d(1024, 256, kernel_size=3, stride=2, padding=1, dilation=1,\n",
    "                                          output_padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.deconv4 = nn.ConvTranspose2d(512, 64, kernel_size=3, stride=2, padding=1, dilation=1,\n",
    "                                          output_padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.deconv5 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.deconv6 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(32)\n",
    "        self.deconv7 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(16)\n",
    "        self.deconv8 = nn.ConvTranspose2d(16, 4, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(4)\n",
    "        self.c8 = nn.Conv2d(4, 4, 6, stride=8, padding=0)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.classifier = nn.Conv2d(4, self.n_class, kernel_size=1)\n",
    "        # self.classifier = nn.Conv2d(4, 1, kernel_size=1)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, images):\n",
    "        x0 = self.resnet[0](images)\n",
    "        x1 = self.resnet[1](x0)\n",
    "        x2 = self.resnet[2](x1)\n",
    "        x3 = self.resnet[3](x2)\n",
    "        x4 = self.resnet[4](x3)\n",
    "        x5 = self.resnet[5](x4)\n",
    "        x6 = self.resnet[6](x5)\n",
    "        out = self.resnet[7](x6)\n",
    "\n",
    "        y1 = self.bn1(self.relu(self.deconv1(out)))\n",
    "        y1 = torch.cat([y1, x6], dim=1)\n",
    "        \n",
    "        y2 = self.bn2(self.relu(self.deconv2(y1)))\n",
    "        y2 = torch.cat([y2, x5], dim=1)\n",
    "        \n",
    "        y3 = self.bn3(self.relu(self.deconv3(y2)))\n",
    "        y3 = torch.cat([y3, x4], dim=1)\n",
    "\n",
    "      \n",
    "        y4 = self.bn4(self.relu(self.deconv4(y3)))\n",
    "        y4 = torch.cat([y4, x2], dim=1)\n",
    " \n",
    "        y5 = self.bn5(self.relu(self.deconv5(y4)))\n",
    "        y6 = self.bn6(self.relu(self.deconv6(y5)))\n",
    "        y7 = self.bn7(self.relu(self.deconv7(y6)))\n",
    "        y8 = self.bn8(self.relu(self.deconv8(y7)))\n",
    "        y9 = self.c8(y8)\n",
    "\n",
    "        # score = self.softmax(self.classifier(y9))\n",
    "        score = self.classifier(y9)\n",
    "        # score = y8\n",
    "        return score\n",
    "\n",
    "torch_model = torch.load('model').eval()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c580c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the saved model\n",
    "# saved_models_dir = os.path.join(os.path.expanduser(\"~\"),\"PycharmProjects\",\"glacier-view-analysis\",  \"src\",\"segmentation\",\"saved_models\")\n",
    "# saved_model_path = os.path.join(saved_models_dir, \"re_ni_sw_de_v1.h5\")\n",
    "\n",
    "# model = keras.models.load_model(saved_model_path, compile = False)\n",
    "#predictions = model.predict(X_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159db2cc-9f6d-4939-8652-25c82b38123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(X_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27706af6-7c34-4484-9238-13020e3cb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "inputs = torch.tensor(X_smoothed)\n",
    "\n",
    "inputs = inputs.permute(0,3,1,2)\n",
    "SMOOTH_FACTOR = 0.0001\n",
    "\n",
    "green = inputs[:,1,:,:]\n",
    "swir = inputs[:,4,:,:]\n",
    "nir = inputs[:,3,:,:]\n",
    "\n",
    "ndsi = (green - swir + SMOOTH_FACTOR)/(green + swir+ SMOOTH_FACTOR)\n",
    "ndsi = ndsi.unsqueeze(dim=1)\n",
    "inputs = torch.cat((ndsi, inputs), dim=1)\n",
    "\n",
    "ndwi = (green - nir + SMOOTH_FACTOR)/(green + nir+ SMOOTH_FACTOR)\n",
    "ndwi = ndwi.unsqueeze(dim=1)\n",
    "inputs = torch.cat((ndwi, inputs), dim=1)\n",
    "\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e77cd-4eb4-4760-838e-6807d6074e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataset = TensorDataset(inputs) # create your datset\n",
    "prediction_dataloader = DataLoader(prediction_dataset, batch_size=64) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b40e8-929b-4755-95eb-3424227054f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in prediction_dataloader:\n",
    "    with torch.no_grad():\n",
    "        outputs = torch_model.forward(i[0].to(device))\n",
    "        outputs = torch.softmax(outputs, dim=1)\n",
    "        outputs = outputs[:,1,:,:].unsqueeze(1)\n",
    "    m = torch.nn.Threshold(PROB_THRESH, 0)\n",
    "    predictions.append(m(outputs))\n",
    "    \n",
    "predictions = torch.cat(predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d7254-3031-4f2f-bf51-d3bc08b3266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8cb1f4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create GIF\n",
    "gif_creation_dir = os.path.join(os.path.expanduser(\"~\"), \"PycharmProjects\",\"glacier-view-analysis\", \"src\", \"segmentation\",\"tmp\",\"gif_creation\")\n",
    "gif_output_dir = os.path.join(os.path.expanduser(\"~\"), \"PycharmProjects\",\"glacier-view-analysis\", \"src\", \"segmentation\", \"gifs\")\n",
    "\n",
    "for f in os.listdir(gif_creation_dir):\n",
    "    os.remove(os.path.join(gif_creation_dir, f))\n",
    "\n",
    "for i in range(X_smoothed.shape[0]):\n",
    "    if i%5 == 0: #ignores 80% of images to run faster\n",
    "        fig, axs = plt.subplots(2, figsize=(10,10)) ##update the number of suplots to equal the number of layers you want to display\n",
    "        fig.suptitle(image_file_names_ordered[i])\n",
    "        axs[0].imshow((X_smoothed[i,:,:,:][:,:,[2,1,0]]))\n",
    "        #axs[0].imshow((X_smoothed[i,:,:,:][:,:,[5]]))\n",
    "        axs[1].imshow(predictions[i,0,:,:]) #\n",
    "\n",
    "        plt.savefig(os.path.join(gif_creation_dir,f'{image_file_names_ordered[i]}.png'), dpi = 100)\n",
    "        # plt.show()\n",
    "\n",
    "with imageio.get_writer(os.path.join(gif_output_dir,f\"{glims_id}.gif\"), mode='I') as writer:\n",
    "    for filename in sorted(os.listdir(gif_creation_dir)):\n",
    "        image = imageio.imread(os.path.join(gif_creation_dir,filename))\n",
    "        writer.append_data(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac542f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate and save surface area time_series\n",
    "\n",
    "ts_output_dir = os.path.join(os.path.expanduser(\"~\"), \"PycharmProjects\",\"glacier-view-analysis\",  \"src\", \"segmentation\", \"surface_area_time_series\")\n",
    "total_areas = []\n",
    "for prediction in predictions:\n",
    "    total_areas.append(np.sqrt(np.sum(prediction)))\n",
    "plt.plot(image_dates, total_areas)\n",
    "plt.title(\"Estimated Surface Area (no units)\")\n",
    "# plt.savefig(os.path.join(ts_output_dir, f\"{glims_id}.png\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234282cc-a8c1-4226-8186-8b4905bee4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
