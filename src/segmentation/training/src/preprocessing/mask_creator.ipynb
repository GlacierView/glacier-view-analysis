{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed631d0",
   "metadata": {},
   "source": [
    "- We have a polygon and we have a list of tifs for a glacier. These tifs almost always are in the same crs and utm zone. Before we smooth the tifs we have to create the masks.\n",
    "- To create the masks we need one tif from each glacier and the polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b84806f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(os.path.expanduser(\"~\"),\"Desktop\",\"projects\", \"GlacierView\", \"src\",\"segmentation\",\"helpers\"))\n",
    "import read\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2841f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_view_dir = os.path.join(os.path.expanduser(\"~\"),\"Desktop\",\"projects\",\"GlacierView\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11b4efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mapping of all glims ids to a CRS\n",
    "training_metadata_path = os.path.join(glacier_view_dir,\"src\",\"earth_engine\",\"data\",\"processed_metadata\",\"localized_time_series_for_segmentation_training_large\",\"ee_metadata.csv\")\n",
    "metadata_df = pd.read_csv(training_metadata_path)\n",
    "metadata_df['glims_id'] = metadata_df.glacier_pk.str.split(\"_\").str[0]\n",
    "metadata_df['crs'] = ['EPSG:326' + str(round(zone)) for zone in metadata_df['utm_zone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bdf8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "glims_id_crs_dict = {}\n",
    "for glims_id, df in metadata_df.groupby(\"glims_id\"):\n",
    "    try: \n",
    "        glims_id_crs_dict[glims_id] = int(df.crs.value_counts().index[0])\n",
    "    except: #for no CRS (very few)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cae1bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reproject the polygons to UTM\n",
    "glims_training_sample_path = os.path.join(glacier_view_dir,\"src\",\"glims\",\"data\",\"training_sample\",\"glims_3000_bb.shp\")\n",
    "polys_df = gpd.read_file(glims_training_sample_path)\n",
    "polys_df.geometry.crs = \"epsg:4326\" #polys are in lat long\n",
    "\n",
    "reprojected_polygons = []\n",
    "crs_list = []\n",
    "for i in range(polys_df.shape[0]):\n",
    "    row = polys_df.iloc[[i],:]\n",
    "    if row.glac_id.iloc[0] in glims_id_crs_dict:\n",
    "        crs = glims_id_crs_dict.get(row.glac_id.iloc[0])\n",
    "        crs_list.append(crs)\n",
    "        reprojected_polygons.append(row.geometry.to_crs(f\"epsg:{crs}\"))\n",
    "    else:\n",
    "        crs_list.append('4326')\n",
    "        reprojected_polygons.append(row.geometry)\n",
    "\n",
    "        poly_list = []\n",
    "for idx, poly in enumerate(reprojected_polygons):\n",
    "    poly_list.append(reprojected_polygons[idx][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baa63ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattw/opt/miniconda3/envs/glaciers-tensorflow/lib/python3.8/site-packages/rasterio/mask.py:88: UserWarning: shapes are outside bounds of raster. Are they in different coordinate reference systems?\n",
      "  warnings.warn('shapes are outside bounds of raster. '\n"
     ]
    }
   ],
   "source": [
    "#obtain masks from polygons\n",
    "landsat_dir = os.path.join(glacier_view_dir,\"src\",\"earth_engine\",\"data\",\"ee_landing_zone\",\"localized_time_series_for_segmentation_training_large\",\"landsat\")\n",
    "poly_glims_ids = polys_df.glac_id\n",
    "\n",
    "mask_dict = {}\n",
    "for glims_id in os.listdir(landsat_dir):\n",
    "    glacier_dir = os.path.join(landsat_dir, glims_id)\n",
    "    try:\n",
    "        tif_name = os.listdir(glacier_dir)[0]\n",
    "        poly_list_loc = np.where(glims_id == poly_glims_ids)[0][0]\n",
    "        with rasterio.open(os.path.join(glacier_dir, tif_name)) as src:\n",
    "            masked, _ = mask(src, [poly_list[poly_list_loc]], nodata = 0)\n",
    "        mask_clean = np.rollaxis(np.where(masked != 0, 1, masked),0,3)[:,:,[0]]\n",
    "        mask_dict[glims_id] = mask_clean\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a957997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save series of masks\n",
    "with open(os.path.join(glacier_view_dir, \"src\",\"segmentation\",\"training\",\"data\",\"training_data_pickles\",\"mask_dict_large.pickle\"),'wb') as handle:\n",
    "    pickle.dump(mask_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b5a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
