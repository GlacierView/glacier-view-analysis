{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.expanduser(\"~\"),\"Desktop\",\"projects\", \"GlacierView\",\n",
    "                                \"src\",\"segmentation\",\"helpers\"))\n",
    "import read, preprocess, explore\n",
    "from tqdm import tqdm\n",
    "\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import geopandas as gpd\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from scipy.stats import logistic\n",
    "import cv2\n",
    "\n",
    "import importlib\n",
    "importlib.reload(read)\n",
    "importlib.reload(preprocess)\n",
    "importlib.reload(explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-birmingham",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221afd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "data_label = \"localized_time_series_for_training_c02_t1_l2\"\n",
    "dem_data_label = \"localized_time_series_for_segmentation_training_large\"\n",
    "dem_label = \"NASADEM\"\n",
    "glacier_view_dir = os.path.join(os.path.expanduser('~'),\"Desktop\",\"projects\",\"GlacierView\")\n",
    "glaciers_dir = os.path.join(glacier_view_dir,\"src\",\"earth_engine\",\"data\",\"ee_landing_zone\",data_label, \"landsat\")\n",
    "dem_dir = os.path.join(glacier_view_dir,\"src\",\"earth_engine\", \"data\",\"ee_landing_zone\",dem_data_label, \"dems\")\n",
    "masks_dir = os.path.join(glacier_view_dir, \"src\",\"segmentation\",\"training\",\"data\",\"masks_staging_2\")\n",
    "log_dir = os.path.join(glacier_view_dir,\"src\",\"earth_engine\",\"data\",\"ee_landing_zone\",data_label, \"logs\")\n",
    "output_dir = os.path.join(glacier_view_dir, \"src\", \"earth_engine\", \"data\", \"processed_metadata\", data_label)\n",
    "log_path =  os.path.join(log_dir,\"training_log_1.log\")\n",
    "glims_ids = sorted([f for f in os.listdir(glaciers_dir) if not f.startswith('.')])\n",
    "\n",
    "#outputs\n",
    "processed_training_data = os.path.join(glacier_view_dir, \"src\",\"segmentation\",\"training\",\"data\",\"processed_training_data_2\")\n",
    "images_write_path = os.path.join(processed_training_data, \"images\")\n",
    "masks_write_path = os.path.join(processed_training_data, \"masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ca19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_bands = ['blue','green','red','nir','swir','thermal']\n",
    "dim = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60052e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completed_glims_ids = os.listdir(images_write_path)\n",
    "# remaining_glims_ids = [i for i in glims_ids if i + '.tif' not in completed_glims_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79247a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dir = os.path.join(glacier_view_dir,\"src\",\"earth_engine\",\"data\",\"processed_metadata\",data_label)\n",
    "df = pd.read_csv(os.path.join(metadata_dir,\"filtered_training_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_num = 5\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    images = {}\n",
    "    dems = {}\n",
    "    masks = {}\n",
    "    \n",
    "    images[row.glims_id] = read.get_rasters(os.path.join(glaciers_dir,row.glims_id),row.file_name )\n",
    "    dems[row.glims_id] = read.get_dem(os.path.join(dem_dir,row.glims_id + '_' + dem_label + '.tif'))\n",
    "    \n",
    "    images[row.glims_id] = preprocess.get_common_bands(images[row.glims_id],common_bands)\n",
    "    images[row.glims_id] = preprocess.normalize_rasters(images[row.glims_id])\n",
    "    images[row.glims_id] = preprocess.resize_rasters(images[row.glims_id],dim)\n",
    "    \n",
    "    dems[row.glims_id] = preprocess.normalize_rasters(dems[row.glims_id])\n",
    "    dems[row.glims_id] = preprocess.resize_rasters(dems[row.glims_id], dim)\n",
    "\n",
    "    mask_file_name = f\"{row.glims_id}.tif\"\n",
    "    try:\n",
    "        img = Image.open(os.path.join(masks_dir, mask_file_name))\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    masks[row.glims_id] = {mask_file_name: np.expand_dims(np.array(img),2)}\n",
    "    masks[row.glims_id] = preprocess.resize_rasters(masks[row.glims_id], dim)\n",
    "\n",
    "    combined_to_stack = []\n",
    "\n",
    "    image = images[row.glims_id]\n",
    "    dem = dems[row.glims_id]\n",
    "    mask = masks[row.glims_id]\n",
    "\n",
    "\n",
    "    X = [np.concatenate((image[file_name], dem[f\"{row.glims_id}_NASADEM.tif\"]),axis = 2) for file_name in image]\n",
    "#     if np.sum(smoothed_image == 0) < 50000: #convert to percent\n",
    "#         combined_to_stack.append(smoothed_image)\n",
    "    X = np.stack(X)\n",
    "    tifffile.imsave(os.path.join(images_write_path,f\"{row.glims_id}.tif\"), X, planarconfig='contig')\n",
    "    tifffile.imsave(os.path.join(masks_write_path,f\"{row.glims_id}.tif\"),mask[f'{row.glims_id}.tif'])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a433f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_num = 5\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    images = {}\n",
    "    dems = {}\n",
    "    masks = {}\n",
    "    \n",
    "    images[row.glims_id] = read.get_rasters(os.path.join(glaciers_dir,row.glims_id),row.file_name )\n",
    "    dems[row.glims_id] = read.get_dem(os.path.join(dem_dir,row.glims_id + '_' + dem_label + '.tif'))\n",
    "    \n",
    "    images[row.glims_id] = preprocess.get_common_bands(images[row.glims_id],common_bands)\n",
    "    images[row.glims_id] = preprocess.normalize_rasters(images[row.glims_id])\n",
    "    images[row.glims_id] = preprocess.resize_rasters(images[row.glims_id],dim)\n",
    "    \n",
    "    dems[row.glims_id] = preprocess.normalize_rasters(dems[row.glims_id])\n",
    "    dems[row.glims_id] = preprocess.resize_rasters(dems[row.glims_id], dim)\n",
    "\n",
    "    mask_file_name = f\"{row.glims_id}.tif\"\n",
    "    try:\n",
    "        img = Image.open(os.path.join(masks_dir, mask_file_name))\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    masks[row.glims_id] = {mask_file_name: np.expand_dims(np.array(img),2)}\n",
    "    masks[row.glims_id] = preprocess.resize_rasters(masks[row.glims_id], dim)\n",
    "\n",
    "    combined_to_stack = []\n",
    "\n",
    "    image = images[row.glims_id]\n",
    "    dem = dems[row.glims_id]\n",
    "    mask = masks[row.glims_id]\n",
    "\n",
    "\n",
    "    X = [np.concatenate((image[file_name], dem[f\"{row.glims_id}_NASADEM.tif\"]),axis = 2) for file_name in image]\n",
    "#     if np.sum(smoothed_image == 0) < 50000: #convert to percent\n",
    "#         combined_to_stack.append(smoothed_image)\n",
    "    X = np.stack(X)\n",
    "    print(row.file_name)\n",
    "    plt.imshow(np.rollaxis(X[0,:,:,[2,1,0]],0,3))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8cb17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd95ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0468a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "glims_ids = list(images.keys())\n",
    "glims_id = glims_ids[1] #modify this index\n",
    "\n",
    "file_names = list(images[glims_id].keys())\n",
    "file_name = file_names[0]\n",
    "img = images[glims_id][file_name]\n",
    "\n",
    "print(f\"{glims_id}/{file_name}\")\n",
    "\n",
    "#/Users/mattw/Desktop/projects/GlacierView/src/earth_engine/data/ee_landing_zone/localized_time_series_for_training_c02_t1_l2/landsat/G268658E81610N/G268658E81610N_2015-08-10_L8_C02_T1_L2_SR.tif\n",
    "#G268658E81610N/G268658E81610N_2015-08-10_L8_C02_T1_L2_SR.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore.view_training_images(X_train, where = 0, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c115aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "#training_data = list(zip(X_train,y_train))\n",
    "#test_data = list(zip(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
