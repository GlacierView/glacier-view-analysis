{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.expanduser(\"~\"),\"Desktop\",\"projects\", \"GlacierView\", \"src\",\"segmentation\",\"helpers\"))\n",
    "import read, preprocess, explore\n",
    "\n",
    "\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import importlib\n",
    "importlib.reload(read)\n",
    "importlib.reload(preprocess)\n",
    "importlib.reload(explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-birmingham",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90697161",
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_view_dir = os.path.join(os.path.expanduser(\"~\"),\"Desktop\",\"projects\",\"GlacierView\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ca19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_data_dir = os.path.join(os.path.expanduser(\"~\"),\n",
    "    \"Desktop\", \"projects\",\"GlacierView\", \"src\", \"earth_engine\",\"data\",\"ee_landing_zone\",\"localized_time_series_for_segmentation_training_large\")\n",
    "landsat_dir = os.path.join(ee_data_dir, \"landsat\")\n",
    "dem_dir = os.path.join(ee_data_dir, \"dems\")\n",
    "masks_path = os.path.join(glacier_view_dir, \"src\",\"segmentation\",\"training\",\"data\",\"training_data_pickles\",\"mask_dict_large.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dict = {}\n",
    "for glacier_dir_name in os.listdir(landsat_dir):\n",
    "    if glacier_dir_name.startswith('.'): \n",
    "        continue #ignores hidden files\n",
    "    glims_id = glacier_dir_name\n",
    "    images_dict[glims_id] = read.get_rasters(os.path.join(landsat_dir,glacier_dir_name))[0]\n",
    "\n",
    "dem_dict = {}\n",
    "for dem_file_name in os.listdir(dem_dir):\n",
    "    glims_id = dem_file_name.split(\"_\")[0]\n",
    "    dem_dict[glims_id] = read.get_dem(os.path.join(dem_dir,dem_file_name))\n",
    "\n",
    "\n",
    "with open(masks_path, \"rb\") as infile:\n",
    "    mask_dict = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (128,128)\n",
    "images_dict_processed = {}\n",
    "for image in images_dict:\n",
    "    images_dict_processed[image] = preprocess.get_common_bands_from_list_of_numpy_arrays(images_dict[image],\n",
    "                                                                            ['red',\n",
    "                                                                             'nir',\n",
    "                                                                             'swir',\n",
    "                                                                             ])\n",
    "    images_dict_processed[image] = preprocess.normalize_rasters(images_dict_processed[image])\n",
    "    images_dict_processed[image] = preprocess.resize_rasters(images_dict_processed[image],dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_dict_processed = {}\n",
    "for dem in dem_dict:\n",
    "    dem_dict_processed[dem] = preprocess.resize_rasters([dem_dict[dem]], dim)\n",
    "    dem_dict_processed[dem] = preprocess.normalize_rasters(dem_dict_processed[dem])\n",
    "\n",
    "mask_dict_processed = {}\n",
    "for mask in mask_dict:\n",
    "    mask_dict_processed[mask] = preprocess.resize_rasters([mask_dict[mask]], dim)\n",
    "    \n",
    "common_set = set(images_dict_processed.keys()).intersection(set(dem_dict_processed.keys())).intersection(set(mask_dict_processed.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 0.5\n",
    "combined_to_stack = []\n",
    "masks = []\n",
    "for glims_id in common_set:\n",
    "    combined_images_and_dems = [np.concatenate((img, dem_dict_processed[glims_id][0]),axis = 2) for img in images_dict_processed[glims_id]]\n",
    "    smoothed_image = np.percentile(np.stack(combined_images_and_dems), percentile, axis = 0)\n",
    "    if np.sum(smoothed_image == 0) < 50000: #convert to percent\n",
    "        combined_to_stack.append(smoothed_image)\n",
    "        masks.append(mask_dict_processed[glims_id][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ce830",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(combined_to_stack)\n",
    "y = np.stack(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9694ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "training_data = list(zip(X_train,y_train))\n",
    "test_data = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ba118",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_pickles_dir = os.path.join(glacier_view_dir, \"src\",\"segmentation\",\"training\",\"data\",\"training_data_pickles\")\n",
    "with open(os.path.join(training_data_pickles_dir,'training_data.pickle'), 'wb') as handle:\n",
    "    pickle.dump(training_data, handle)\n",
    "\n",
    "with open(os.path.join(training_data_pickles_dir,'test_data.pickle'), 'wb') as handle:\n",
    "    pickle.dump(test_data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.view_training_images(X_train, where = 0, n=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
